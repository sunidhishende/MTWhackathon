{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_data = pd.read_csv('./data/card_transaction.v1.csv')\n",
    "mcc = pd.read_csv(\"./data/mcc_codes.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the main_data with the mcc dataset on the 'MCC' column\n",
    "data = pd.merge(main_data, mcc, left_on='MCC', right_on='mcc')\n",
    "del main_data, mcc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def convert_to_utc(data):\n",
    "    \n",
    "    year, month, day, time_str = data\n",
    "    time_obj = datetime.strptime(time_str, \"%H:%M\").time()\n",
    "    \n",
    "    # Create full datetime object (assuming UTC)\n",
    "    dt_obj = datetime(year, month, day, time_obj.hour, time_obj.minute)\n",
    "    \n",
    "    # Convert to UTC timestamp string\n",
    "    return dt_obj.isoformat() + \"Z\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pqdm.processes import pqdm as pqdm_processes\n",
    "from pqdm.threads import pqdm as pqdm_threads\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def categorical_labeling(values):\n",
    "    label_encoder = LabelEncoder()\n",
    "    # Fit and transform the values\n",
    "    encoded_values = label_encoder.fit_transform(values)\n",
    "    return np.array(encoded_values), label_encoder\n",
    "\n",
    "def get_reverse_mapping(label_encoder):\n",
    "    \"\"\"\n",
    "    Given a fitted LabelEncoder, returns a dictionary mapping class ids to the original class labels.\n",
    "    \"\"\"\n",
    "    reverse_map = {i: label for i, label in enumerate(label_encoder.classes_)}\n",
    "    return reverse_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['UTC_Timestamp'] = [convert_to_utc(item) for item in tqdm(data[['Year', 'Month', 'Day', 'Time']].values)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['UTC_Timestamp'] = pd.to_datetime(data['UTC_Timestamp'])\n",
    "data = data.sort_values(by=['User', 'Card', 'UTC_Timestamp'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "103986"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['city_labeled'], le = categorical_labeling(data['Merchant City'])\n",
    "open('temp.txt', 'w').write(str(get_reverse_mapping(le)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2215"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data['Amount'] = data['Amount'].map(lambda x: float(x[1:]))\n",
    "\n",
    "data['has_error'] = (data['Errors?'].isna() == False).astype(int)\n",
    "\n",
    "data['Minutes_Since_Midnight'] = data['Time'].apply(lambda t: int(t.split(':')[0]) * 60 + int(t.split(':')[1]))\n",
    "\n",
    "data.fillna({'irs_reportable': 'NA'}, inplace=True)\n",
    "data.fillna({'irs_description': 'NA'}, inplace=True)\n",
    "data['irs_reportable_labeled'], irs_report_le = categorical_labeling(data['irs_reportable'])\n",
    "data['irs_description_labeled'], irs_desc_le = categorical_labeling(data['irs_description'])\n",
    "\n",
    "data['Is_Fraud_Binary'] = data['Is Fraud?'].map({'Yes': 1, 'No': 0})\n",
    "data['Use_chip_labeled'] = data['Use Chip'].map({'Swipe Transaction': 0, 'Online Transaction': 1, 'Chip Transaction': 2})\n",
    "data['city_labeled'], city_le = categorical_labeling(data['Merchant City'])\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_features = ['Month', 'Day', 'MCC', 'Minutes_Since_Midnight', 'city_labeled', 'Use_chip_labeled', 'Amount', 'has_error', 'irs_reportable_labeled', 'irs_description_labeled']\n",
    "filtered_data = data[seq_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pkl.dump(filtered_data, open('./data/engineered_data.pkl', 'wb'))\n",
    "pkl.dump(data, open('./data/engineered_data_raw.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_data = pkl.load(open('./data/engineered_data.pkl', 'rb'))\n",
    "data = pkl.load(open('./data/engineered_data_raw.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_features = ['Month', 'Day', 'MCC', 'Minutes_Since_Midnight', 'city_labeled', 'Use_chip_labeled', 'Amount', 'has_error', 'irs_reportable_labeled', 'irs_description_labeled']\n",
    "# filtered_data = data[seq_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data['User'].astype(int).isin(list(range(100)))]\n",
    "filtered_data = data[seq_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl.dump(data, open('./backend/objects/transactions', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import seaborn as sns\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # Convert 'Is Fraud?' column to binary (Yes=1, No=0)\n",
    "# data['Is_Fraud_Binary'] = data['Is Fraud?'].map({'Yes': 1, 'No': 0})\n",
    "# data['Use_chip_labeled'] = data['Use Chip'].map({'Swipe Transaction': 0, 'Online Transaction': 1, 'Chip Transaction': 2})\n",
    "# data['city_labeled'] = categorical_labeling(data['Merchant City'])\n",
    "# # Select numerical columns for correlation analysis\n",
    "# numerical_cols = ['Day', 'MCC', 'Minutes_Since_Midnight', 'city_labeled', 'Amount', 'Use_chip_labeled', 'Is_Fraud_Binary']\n",
    "\n",
    "# # Compute correlation matrix\n",
    "# correlation_matrix = data[numerical_cols].corr()\n",
    "\n",
    "# # Visualize correlation using a heatmap\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# sns.heatmap(correlation_matrix, annot=True, cmap=\"coolwarm\", fmt=\".2f\")\n",
    "# plt.title(\"Feature Correlation with Fraud\")\n",
    "# plt.show()\n",
    "\n",
    "# # Display sorted correlation values with 'Is Fraud?'\n",
    "# correlation_with_fraud = correlation_matrix['Is_Fraud_Binary'].drop('Is_Fraud_Binary').sort_values(ascending=False)\n",
    "# correlation_with_fraud\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.metrics import classification_report, confusion_matrix\n",
    "# from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# # Assuming `subset_df` is your dataframe with all required columns.\n",
    "# # The target column should be binary (e.g., 'Is_Fraud_Binary'), and the features are:\n",
    "# features = ['Month', 'Day', 'MCC', 'Minutes_Since_Midnight', 'city_labeled', 'Use_chip_labeled', 'Amount', 'has_error', 'irs_reportable_labeled', 'irs_description_labeled']\n",
    "# target = 'Is_Fraud_Binary'\n",
    "\n",
    "# # Extract features and target from the dataframe\n",
    "# X = data[features]\n",
    "# y = data[target]\n",
    "\n",
    "# # Perform a train/test split with stratification to preserve class distribution\n",
    "# X_train, X_test, y_train, y_test = train_test_split(\n",
    "#     X, y, test_size=0.3, stratify=y, random_state=42\n",
    "# )\n",
    "\n",
    "# # Address class imbalance using SMOTE on the training set\n",
    "# smote = SMOTE(random_state=42)\n",
    "# X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# # Define individual strong predictors\n",
    "# clf_rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "# clf_gb = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
    "# clf_lr = LogisticRegression(max_iter=1000, random_state=42)\n",
    "\n",
    "# # Build a soft-voting ensemble classifier\n",
    "# ensemble = VotingClassifier(\n",
    "#     estimators=[('rf', clf_rf), ('gb', clf_gb), ('lr', clf_lr)],\n",
    "#     voting='soft'\n",
    "# )\n",
    "\n",
    "# # Train the ensemble model on the resampled (balanced) training data\n",
    "# ensemble.fit(X_train_res, y_train_res)\n",
    "\n",
    "# # Make predictions on the test set\n",
    "# y_pred = ensemble.predict(X_test)\n",
    "\n",
    "# # Evaluate the model's performance\n",
    "# print(\"Classification Report:\")\n",
    "# print(classification_report(y_test, y_pred))\n",
    "# print(\"Confusion Matrix:\")\n",
    "# print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WINDOW_SIZE=20\n",
    "seq_features = ['Month', 'Day', 'MCC', 'Minutes_Since_Midnight', 'city_labeled', 'Use_chip_labeled', 'Amount', 'has_error', 'irs_reportable_labeled', 'irs_description_labeled']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from multiprocessing import Pool\n",
    "from tqdm import tqdm\n",
    "\n",
    "NUM_PROCESSES = 12  \n",
    "\n",
    "def process_user_card_group(args):\n",
    "    \"\"\"\n",
    "    Process a single user-card group in parallel.\n",
    "    Extracts sequences and aggregated features, including additional behavioral and frequency-based features.\n",
    "    \"\"\"\n",
    "    user_card, group, window_size, feature_cols, target_col = args\n",
    "    group = group.sort_values(by='UTC_Timestamp')\n",
    "    arr = group[feature_cols].values\n",
    "    \n",
    "    X_seq_local, X_agg_local, y_local = [], [], []\n",
    "    \n",
    "    # Get feature indices for amount and categorical features\n",
    "    if 'Amount' in feature_cols:\n",
    "        amount_idx = feature_cols.index('Amount')\n",
    "    else:\n",
    "        amount_idx = None\n",
    "    \n",
    "    if 'MCC' in feature_cols:\n",
    "        mcc_idx = feature_cols.index('MCC')\n",
    "    else:\n",
    "        mcc_idx = None\n",
    "    \n",
    "    if 'Merchant_ID' in feature_cols:\n",
    "        merchant_idx = feature_cols.index('Merchant_ID')\n",
    "    else:\n",
    "        merchant_idx = None\n",
    "\n",
    "    for i in range(window_size, len(group)):\n",
    "        seq_window = arr[i - window_size:i]  # (window_size, num_features)\n",
    "        X_seq_local.append(seq_window)\n",
    "\n",
    "        # Compute basic aggregated statistics\n",
    "        agg_mean = seq_window.mean(axis=0)\n",
    "        agg_std = seq_window.std(axis=0)\n",
    "        agg_min = seq_window.min(axis=0)\n",
    "        agg_max = seq_window.max(axis=0)\n",
    "        agg_range = agg_max - agg_min\n",
    "\n",
    "        # Transaction Frequency Features\n",
    "        timestamps = group.iloc[i - window_size:i]['UTC_Timestamp']\n",
    "        time_diffs = timestamps.diff().dt.total_seconds().dropna().values  # Time differences in seconds\n",
    "\n",
    "        avg_time_diff = np.mean(time_diffs) if len(time_diffs) > 0 else 0\n",
    "        max_time_diff = np.max(time_diffs) if len(time_diffs) > 0 else 0\n",
    "        min_time_diff = np.min(time_diffs) if len(time_diffs) > 0 else 0\n",
    "\n",
    "        # Large Transactions Features\n",
    "        if amount_idx is not None:\n",
    "            amounts = seq_window[:, amount_idx]\n",
    "            high_value_txns = np.sum(amounts > np.percentile(amounts, 75)) / window_size  # % of high-value transactions\n",
    "            rolling_sum = np.sum(amounts)\n",
    "            rolling_avg = np.mean(amounts)\n",
    "        else:\n",
    "            high_value_txns, rolling_sum, rolling_avg = 0, 0, 0\n",
    "\n",
    "        # Merchant & MCC Diversity Features\n",
    "        if merchant_idx is not None:\n",
    "            unique_merchants = len(set(seq_window[:, merchant_idx]))\n",
    "        else:\n",
    "            unique_merchants = 0\n",
    "\n",
    "        if mcc_idx is not None:\n",
    "            unique_mcc_codes = len(set(seq_window[:, mcc_idx]))\n",
    "        else:\n",
    "            unique_mcc_codes = 0\n",
    "\n",
    "        # Combine all features\n",
    "        agg_features = np.concatenate([\n",
    "            agg_mean, agg_std, agg_min, agg_max, agg_range,\n",
    "            [avg_time_diff, max_time_diff, min_time_diff],  # Transaction frequency\n",
    "            [high_value_txns, rolling_sum, rolling_avg],    # Large transaction features\n",
    "            [unique_merchants, unique_mcc_codes]           # Merchant & MCC diversity\n",
    "        ])\n",
    "\n",
    "        X_agg_local.append(agg_features)\n",
    "        y_local.append(group.iloc[i][target_col])\n",
    "\n",
    "    return X_seq_local, X_agg_local, y_local\n",
    "\n",
    "def create_sequences_parallel(df, window_size=10, feature_cols=[], target_col='Is_Fraud_Binary'):\n",
    "    \"\"\"\n",
    "    Process the user-card groups in parallel to speed up sequence generation.\n",
    "    \"\"\"\n",
    "    grouped_data = [(key, group, window_size, feature_cols, target_col) for key, group in df.groupby(['User', 'Card'])]\n",
    "    \n",
    "    # Use multiprocessing Pool to process groups in parallel\n",
    "    with Pool(NUM_PROCESSES) as pool:\n",
    "        results = list(tqdm(pool.imap(process_user_card_group, grouped_data), total=len(grouped_data)))\n",
    "    \n",
    "    # Combine results from all processes\n",
    "    X_seq, X_agg, y = [], [], []\n",
    "    for X_s, X_a, y_l in results:\n",
    "        X_seq.extend(X_s)\n",
    "        X_agg.extend(X_a)\n",
    "        y.extend(y_l)\n",
    "    \n",
    "    return np.array(X_seq), np.array(X_agg), np.array(y)\n",
    "\n",
    "# Example usage:\n",
    "X_seq, X_agg, y = create_sequences_parallel(data, window_size=20, feature_cols=seq_features)\n",
    "\n",
    "print(\"X_seq shape:\", X_seq.shape)   # (num_samples, WINDOW_SIZE, num_features)\n",
    "print(\"X_agg shape:\", X_agg.shape)     # New feature set including behavior-based features\n",
    "print(\"y shape:\", y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, LSTM, GRU, Conv1D, GlobalAveragePooling1D, Dropout, LayerNormalization, MultiHeadAttention, Flatten\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and testing sets (stratify to preserve fraud ratios)\n",
    "X_seq_train, X_seq_test, X_agg_train, X_agg_test, y_train, y_test = train_test_split(\n",
    "    X_seq, X_agg, y, test_size=0.3, stratify=y, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_agg, y, test_size=0.3, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_nonfraud = X_train[y_train == 0]\n",
    "\n",
    "iso_forest = IsolationForest(n_estimators=100, contamination=0.001, random_state=42)\n",
    "iso_forest.fit(X_train_nonfraud)\n",
    "\n",
    "# Compute anomaly scores for both training and testing data.\n",
    "# The decision_function returns higher values for \"normal\" points.\n",
    "train_scores = iso_forest.decision_function(X_train).reshape(-1, 1)\n",
    "test_scores = iso_forest.decision_function(X_test).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl.dump(iso_forest, open('./backend/models/iso_forest', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# 3. Stage 2: Append Anomaly Scores and Train a Cost-Sensitive Classifier\n",
    "# ---------------------------\n",
    "# Append the anomaly scores as a new feature\n",
    "X_train_aug = np.concatenate([X_train, train_scores], axis=1)\n",
    "X_test_aug = np.concatenate([X_test, test_scores], axis=1)\n",
    "\n",
    "# Compute the scale_pos_weight to counter class imbalance\n",
    "neg_count = np.sum(y_train == 0)\n",
    "pos_count = np.sum(y_train == 1)\n",
    "scale_pos_weight = neg_count / pos_count\n",
    "\n",
    "# Train an XGBoost classifier with cost sensitivity\n",
    "xgb_model = XGBClassifier(n_estimators=100, scale_pos_weight=scale_pos_weight,\n",
    "                          random_state=42, use_label_encoder=False, eval_metric='logloss')\n",
    "xgb_model.fit(X_train_aug, y_train)\n",
    "\n",
    "# ---------------------------\n",
    "# 4. Evaluate the Ensemble Model\n",
    "# ---------------------------\n",
    "y_pred = xgb_model.predict(X_test_aug)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import precision_recall_curve, classification_report, confusion_matrix\n",
    "\n",
    "# Step 1: Get predicted fraud probabilities from the trained model\n",
    "y_probs = xgb_model.predict_proba(X_test_aug)[:, 1]  # Get fraud probabilities\n",
    "\n",
    "# Step 2: Compute Precision-Recall Curve\n",
    "precisions, recalls, thresholds = precision_recall_curve(y_test, y_probs)\n",
    "\n",
    "# Step 3: Plot Precision-Recall Curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(thresholds, precisions[:-1], \"b--\", label=\"Precision\")\n",
    "plt.plot(thresholds, recalls[:-1], \"r-\", label=\"Recall\")\n",
    "plt.xlabel(\"Threshold\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.title(\"Precision-Recall vs Threshold\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "# Step 4: Choose Best Threshold\n",
    "# We want a balance between Precision and Recall (e.g., F1-score maximization)\n",
    "f1_scores = 2 * (precisions * recalls) / (precisions + recalls)\n",
    "best_threshold = thresholds[np.argmax(f1_scores)]\n",
    "\n",
    "print(f\"Optimal Decision Threshold: {best_threshold:.3f}\")\n",
    "\n",
    "# Step 5: Use the new threshold for final fraud classification\n",
    "y_pred_adjusted = (y_probs >= 0.4).astype(int)\n",
    "\n",
    "# Step 6: Evaluate Model with New Threshold\n",
    "print(\"Classification Report with Adjusted Threshold:\")\n",
    "print(classification_report(y_test, y_pred_adjusted))\n",
    "\n",
    "print(\"Confusion Matrix with Adjusted Threshold:\")\n",
    "print(confusion_matrix(y_test, y_pred_adjusted))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl.dump(xgb_model, open('./backend/models/xgb_model', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from xgboost import plot_importance\n",
    "\n",
    "plot_importance(xgb_model)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Get feature importance values\n",
    "feature_importance = xgb_model.get_booster().get_score(importance_type='weight')\n",
    "\n",
    "# Convert to DataFrame\n",
    "feature_importance_df = pd.DataFrame(feature_importance.items(), columns=['Feature', 'Importance'])\n",
    "\n",
    "# Sort by importance\n",
    "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Display top features\n",
    "print(\"Top Important Features:\")\n",
    "print(feature_importance_df.head(20))\n",
    "\n",
    "# Display least important features\n",
    "print(\"\\nLeast Important Features:\")\n",
    "print(feature_importance_df.tail(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set threshold for feature selection\n",
    "importance_threshold = 50  # Adjust this based on results\n",
    "\n",
    "# Get low-importance features\n",
    "low_importance_features = feature_importance_df[feature_importance_df['Importance'] < importance_threshold]['Feature'].tolist()\n",
    "\n",
    "print(f\"\\nRemoving {len(low_importance_features)} low-importance features:\\n{low_importance_features}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 2: Identify Features to Remove\n",
    "importance_threshold = 50  # Set threshold (Adjust if needed)\n",
    "\n",
    "# Get feature indices that are below the threshold\n",
    "low_importance_indices = feature_importance_df[feature_importance_df['Importance'] < importance_threshold]['Feature_Index'].tolist()\n",
    "\n",
    "# Step 3: Remove Low-Importance Features from NumPy Arrays\n",
    "X_train_reduced = np.delete(X_train, low_importance_indices, axis=1)\n",
    "X_test_reduced = np.delete(X_test, low_importance_indices, axis=1)\n",
    "\n",
    "# Retrain the model on the reduced feature set\n",
    "xgb_model_reduced = XGBClassifier(n_estimators=100, scale_pos_weight=scale_pos_weight,\n",
    "                                  random_state=42, use_label_encoder=False, eval_metric='logloss')\n",
    "xgb_model_reduced.fit(X_train_reduced, y_train)\n",
    "\n",
    "# Evaluate the new model\n",
    "y_probs_reduced = xgb_model_reduced.predict_proba(X_test_reduced)[:, 1]\n",
    "y_pred_adjusted_reduced = (y_probs_reduced >= 0.4).astype(int)\n",
    "\n",
    "print(\"\\nClassification Report after Feature Selection:\")\n",
    "print(classification_report(y_test, y_pred_adjusted_reduced))\n",
    "\n",
    "print(\"\\nConfusion Matrix after Feature Selection:\")\n",
    "print(confusion_matrix(y_test, y_pred_adjusted_reduced))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
